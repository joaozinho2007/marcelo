{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUWO5QkC_g-4"
      },
      "source": [
        "O **Tiro com Arco** é um jogo em que os jogadores atiram flechas de ponta afiada em um alvo redondo com 10 anéis.\n",
        "\n",
        "<img src=\"https://s3-whjr-curriculum-uploads.whjr.online/4de9132a-c71d-42ce-9099-3293e8805fd9.jpg\"> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QtHLAqv3wP3"
      },
      "source": [
        "## Problema de Aprendizado por Reforço (RL) a Resolver\n",
        "Acerte o centro do alvo que proporciona a recompensa máxima"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Osb6FQ74YZtE"
      },
      "source": [
        "<img src=\"https://s3-whjr-curriculum-uploads.whjr.online/40656a8c-14e2-4dd7-9f9e-4c17669b9182.png\" width=300>\n",
        "\n",
        "\n",
        "Número de **Estados**: ?\n",
        "\n",
        "Número de **Ações**: ?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "miKQCNS1jtW2"
      },
      "outputs": [],
      "source": [
        "#importe as bibliotecas\n",
        "import numpy as np\n",
        "\n",
        "# Numero de estados e ações\n",
        "num_estados = 5\n",
        "num_acoes = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ujmi3BO54LfJ"
      },
      "source": [
        "## Matriz de Recompensas\n",
        "A Matriz de Recompensas representa os estados como linhas e as ações como colunas com os respectivos valores de recompensas atribuídos a um determinado par de estado e ação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TM8C0P1_j0h8"
      },
      "outputs": [],
      "source": [
        "#Defina a matriz de recompensas\n",
        "reward_matrix = np.array([[0, -10, -10],  # Estado 0\n",
        "    [-10, 10, -10],  # Estado 1\n",
        "    [-10, -10, 10],  # Estado 2\n",
        "    [-10, 10, -10],  # Estado 3\n",
        "    [-10, -10, 0]    # Estado 4\n",
        "    ])\n",
        "\n",
        "# Matriz Q iniclamente todos os elementos zerados\n",
        "Q_matrix = np.zeros((num_estados, num_acoes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af-CAmdfkDQY"
      },
      "source": [
        "## Execute Ações Aleatoriamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MotipYImkFmN"
      },
      "outputs": [],
      "source": [
        "#Defina shoot()\n",
        "def shoot():\n",
        "    return np.random.randint(num_acoes)\n",
        "\n",
        "#Executar a ação\n",
        "def take_action(state, reward_matrix):\n",
        "    action = shoot()\n",
        "    reward = reward_matrix[state, action]\n",
        "    print(f\"Ação escolhida: {action}, Recompensa: {reward}\")\n",
        "\n",
        "    #Testando a função take action\n",
        "    estado_atual = 2\n",
        "    acao, recompensa = take_action(estado_atual, reward_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXKyVT28hHoH"
      },
      "source": [
        "##Matriz Q\n",
        "O **Aprendizado Q** é um algoritmo de aprendizado por reforço. Dado o estado atual, ele ajuda a encontrar a melhor ação a ser tomada pelo agente.\n",
        "\n",
        "A **Matriz Q** representa a recompensa recebida após uma ação específica no estado atual. Inicialmente, todos os elementos da matriz Q estão zerados.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3ks5cRmkkSrH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Matriz Q inicial:\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "#Crie a matriz Q\n",
        "print(\"\\nMatriz Q inicial:\")\n",
        "print(Q_matrix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZWfKn6wkw6f"
      },
      "source": [
        "##Execute uma Ação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BuLjlxo4kIhU"
      },
      "outputs": [],
      "source": [
        "#Defina take_action\n",
        "\n",
        "def take_action(reward_matrix):\n",
        "  \n",
        "     #Chame a função shoot() para obter a ação\n",
        "     action = shoot()\n",
        "     #Imprima a ação\n",
        "     print(f\"Ação escolhida: {action}\")\n",
        "     #Obtenha a recompensa correspondente usando a matriz de recompensas\n",
        "     reward = reward_matrix[num_estados, action]\n",
        "     #Imprima a recompensa\n",
        "     print(f\"Recompensa obtida: {reward}\")\n",
        "\n",
        "     return action, reward\n",
        "\n",
        "#Teste a função take_action\n",
        "estado_atual = 2\n",
        "#acao, recompensa = take_action(estado_atual, reward_matrix)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "PRO-C125-Project-Boilerplate-Code(pt).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
